---
title: "Ego-exo4d: Understanding skilled human activity from first-and third-person perspectives"
collection: publications
category: conferences
permalink: /publication/EgoExo4D
excerpt: 'This paper is about fixing template issue #693.'
date: '2025'
venue: 'WACV 2025'
paperurl: 'https://arxiv.org/pdf/2412.02903'
bibtexurl: 'http://academicpages.github.io/files/bibtex1.bib'
citation: 'Escobar, M., Puentes, J., Forigua, C., Pont-Tuset, J., Maninis, K. K., & Arbelaez, P. (2025, February). Egocast: Forecasting egocentric human pose in the wild. In 2025 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) (pp. 5831-5841). IEEE.'
---

Abstract
====
We present Ego-Exo4D a diverse large-scale multimodal multiview video dataset and benchmark challenge. Ego-Exo4D centers around simultaneously-captured egocentric and exocentric video of skilled human activities (e.g. sports music dance bike repair). 740 participants from 13 cities worldwide performed these activities in 123 different natural scene contexts yielding long-form captures from 1 to 42 minutes each and 1286 hours of video combined. The multimodal nature of the dataset is unprecedented: the video is accompanied by multichannel audio eye gaze 3D point clouds camera poses IMU and multiple paired language descriptions---including a novel "expert commentary" done by coaches and teachers and tailored to the skilled-activity domain. To push the frontier of first-person video understanding of skilled human activity we also present a suite of benchmark tasks and their annotations including fine-grained activity understanding proficiency estimation cross-view translation and 3D hand/body pose. All resources are open sourced to fuel new research in the community.